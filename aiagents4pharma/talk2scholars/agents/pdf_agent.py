#!/usr/bin/env python3
"""
Agent for interacting with PDF documents via QnA.

This module initializes and compiles a LangGraph application that enables users to query PDF
documents using a question-and-answer tool. It integrates a language model and follows
the ReAct pattern to process and answer queries related to PDF content.

Usage:
    >>> app = get_app("unique_thread_id")
    >>> response = app.invoke(initial_state)
"""

import logging
import hydra
from omegaconf import OmegaConf
from langchain_openai import ChatOpenAI
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import create_react_agent, ToolNode
from langgraph.checkpoint.memory import MemorySaver
from ..state.state_talk2scholars import Talk2Scholars
from ..tools.pdf.qna import qna_tool
from ..tools.s2.query_results import query_results

# Initialize logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def get_app(uniq_id, llm_model="gpt-4o-mini"):
    """
    Initializes and returns the LangGraph application for the PDF QnA agent.

    This function sets up the PDF agent by loading configuration settings via Hydra,
    initializing a model, and creating a workflow graph that incorporates
    PDF-specific tools. The agent is built using the ReAct pattern to facilitate interactive
    querying and processing of PDF documents.

    Args:
        uniq_id (str): A unique identifier for the current conversation session or thread.
        llm_model (str, optional): The identifier for the language model to be used. If None, the
            model specified in the configuration is used. Defaults to "gpt-4o-mini".

    Returns:
        StateGraph: A compiled LangGraph application capable of handling PDF QnA interactions.

    Example:
        >>> app = get_app("thread_123")
        >>> result = app.invoke(initial_state)
    """
    # Load configuration using Hydra.
    with hydra.initialize(
        version_base=None,
        config_path="../../configs/agents/talk2scholars/pdf_agent"
    ):
        cfg = hydra.compose(config_name="default")
        logger.info("Loaded pdf_agent configuration:\n%s", OmegaConf.to_yaml(cfg))

    # Use the configuration to set the model if none is provided.
    if llm_model is None:
        llm_model = cfg.openai_llms[0] if cfg.openai_llms else "gpt-4o-mini"

    def agent_pdf_node(state: Talk2Scholars):
        """
        Processes the current state by invoking the language model for PDF QnA.

        This node takes the existing conversation state and calls the configured language model to
        generate a response based on the PDF QnA context, using the provided thread identifier for
        configuration purposes.

        Args:
            state (Talk2Scholars): The current conversation state containing query details and
                context.

        Returns:
            Any: The response generated by the language model after processing the state.

        Example:
            >>> response = agent_pdf_node(current_state)
        """
        logger.info("Creating Agent_PDF node with thread_id %s", uniq_id)
        response = model.invoke(state, {"configurable": {"thread_id": uniq_id}})
        return response

    # Define the tool node that includes the PDF QnA tool.
    tools = ToolNode([qna_tool, query_results])

    # Initialize the OpenAI model using configuration values.
    logger.info("Using OpenAI model %s", llm_model)
    llm = ChatOpenAI(model=llm_model, temperature=cfg.temperature)

    # Create the agent.
    model = create_react_agent(
        llm,
        tools=tools,
        state_schema=Talk2Scholars,
        state_modifier=cfg.pdf_agent,
        checkpointer=MemorySaver(),
    )

    # Define a new workflow graph with the state schema.
    workflow = StateGraph(Talk2Scholars)
    workflow.add_node("agent_pdf", agent_pdf_node)
    workflow.add_edge(START, "agent_pdf")

    # Initialize memory to persist state between runs.
    checkpointer = MemorySaver()

    # Compile the graph into a runnable app.
    app = workflow.compile(checkpointer=checkpointer)
    logger.info("Compiled the PDF QnA agent graph.")

    return app
